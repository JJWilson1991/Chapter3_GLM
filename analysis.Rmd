---
title: "Untitled"
author: "JJW"
date: "2022-11-21"
output: html_document
---

```{r load packages}

library(dplyr)
library(DataExplorer)
library(ggplot2)
library(ggsignif)
#library(glm)
library(stats)
library(magrittr)
library(MASS)
library(caret)
```

```{r load data}
#remove scientific notation of numbers
options(scipen=999)
#load data
SCWDS_with_eco<-read.csv("Complete_data_CDV_vars.csv")

#filter out NAs
SCWDS_with_eco_fil1<-SCWDS_with_eco%>%dplyr::filter(!is.na(description))

```

```{r create report}
#create_report(SCWDS_with_eco_fil1)



```

```{r}
#recode distemper as 1/0
SCWDS_with_eco_fil1$Distemper<-ifelse(SCWDS_with_eco_fil1$Distemper=="Y",1,0)

table(SCWDS_with_eco_fil1$Distemper)


#filter variables for GLM
SCWDS_with_eco_fil2<-SCWDS_with_eco_fil1[,c(2,6,8,9,13,16,17,19,20,21,22,27,28,24,25,10)]

SCWDS_with_eco_fil2$State%<>%as.factor()

SCWDS_with_eco_fil2%<>% mutate(Sex= na_if(Sex, "Unknown"))%>%mutate(Age= na_if(Age, "Unknown"))

state_species_tab<-addmargins(table(SCWDS_with_eco_fil2$State,SCWDS_with_eco_fil2$Species))
write.csv(state_species_tab, "state_species.csv")


SCWDS_rac<-SCWDS_with_eco_fil2%>%dplyr::filter(Species=="Raccoon")
```

```{r}
# box plot imp
ggplot(SCWDS_with_eco, aes(x = Distemper, y = Imperviousness)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)


```

```{r}
# box plot knn
ggplot(SCWDS_with_eco, aes(x = Distemper, y = knn.dist)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)


anovaknn <- aov(knn.dist~Distemper, SCWDS_with_eco)
summary(anovaknn)

```

```{r}
# box plot temp
ggplot(SCWDS_with_eco, aes(x = Distemper, y = Temperature)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)


```
```{r}
# box plot ppt
ggplot(SCWDS_with_eco, aes(x = Distemper, y = Precipitation)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)



anovappt <- aov(Precipitation~Distemper, SCWDS_with_eco)
summary(anovappt)
```

```{r}
# box plot imo
ggplot(SCWDS_with_eco, aes(x = Distemper, y = lat)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)


```
```{r}
# box plot imo
ggplot(SCWDS_with_eco, aes(x = Distemper, y = long)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)


```

```{r}
# box plot imo
ggplot(SCWDS_with_eco, aes(x = Distemper, y = Elevation)) +
    geom_boxplot() +
    stat_summary(fun.y = mean,
        geom = "point",
        size = 3,
        color = "steelblue") +
    theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("N", "Y")), 
              map_signif_level=TRUE)


```







```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=class, fill=Distemper))+ geom_bar()


```


```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=description, fill=Distemper))+ geom_bar()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))




```


```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=month, fill=Distemper))+ geom_bar()


```

```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=Sex, fill=Distemper))+ geom_bar()#+geom_signif(comparisons = list(c("Female", "Male")),  map_signif_level=TRUE)


```
```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=Species, fill=Distemper))+ geom_bar()


```


```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=State, fill=Distemper))+ geom_bar()


```


```{r}
#bar chart 
ggplot(SCWDS_with_eco, aes(x=Age, fill=Distemper))+ geom_bar()


```


```{r}
#bar chart 
kl<-data.frame(table(SCWDS_with_eco$year_month, SCWDS_with_eco$Distemper))
ggplot(kl, aes(x=Var1, y=Freq, colour=Var2))+geom_point()+geom_smooth()


ggplot(SCWDS_with_eco, aes(x=year_month, fill=Distemper))+ geom_bar(position = "dodge")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```

```{r}
#bar chart 

kl2<-data.frame(table(SCWDS_with_eco$month, SCWDS_with_eco$Distemper))
ggplot(kl2, aes(x=Var1, y=Freq, colour=Var2))+geom_point()+geom_smooth()


#ggplot(SCWDS_with_eco, aes(x=month, fill=Distemper))+ geom_point()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```

###GLM

```{r}
#randomise order of cases 
#SCWDS_with_eco_fil2<-SCWDS_with_eco_fil2[sample(1:nrow(SCWDS_with_eco_fil2)), ]

SCWDS_with_eco_fil2<-SCWDS_with_eco_fil2[-(1)]
SCWDS_with_eco_fil2<-SCWDS_with_eco_fil2[-(13)]
SCWDS_with_eco_fil2$Species%<>%as.factor()
SCWDS_with_eco_fil2$Sex%<>%as.factor()
SCWDS_with_eco_fil2$Age%<>%as.factor()
SCWDS_with_eco_fil2$description%<>%as.factor()

set.seed(345)

#create function to split into traiing and test data sets
create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
data_train <- create_train_test(SCWDS_with_eco_fil2, 0.8, train = TRUE)
data_test <- create_train_test(SCWDS_with_eco_fil2, 0.8, train = FALSE)
dim(data_train)


formula <- Distemper~.
logit <- glm(formula, data = data_train, family = 'binomial')
summary(logit)
levels(data_test$State)


#data_test_new <- data_test                                # Duplicate test data set
#data_test_new$x[which(!(data_test_new$State %in% unique(data_train$State)))] <- NA  # Replace new levels by NA
#data_test_new        
predict <- predict(logit, data_test, type = 'response')
# confusion matrix
table_mat <- table(data_test$Distemper, predict >0.5)
table_mat

accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test


precision <- function(matrix) {
	# True positive
    tp <- matrix[2, 2]
	# false positive
    fp <- matrix[1, 2]
    return (tp / (tp + fp))
}

recall <- function(matrix) {
# true positive
    tp <- matrix[2, 2]# false positive
    fn <- matrix[2, 1]
    return (tp / (tp + fn))
}

prec <- precision(table_mat)
prec
rec <- recall(table_mat)
rec


f1 <- 2 * ((prec * rec) / (prec + rec))
f1
```
```{r streamline model}

#test for interaction
add1(logit, scope = .~. + .^2, test="Chisq")

add1.test <- add1(logit, scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$`Pr(>Chi)`),]

add1.test <- add1(update(logit, .~. + Species:knn.dist), scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$`Pr(>Chi)`),]

add1.test <- add1(update(logit, .~. + Species:knn.dist+ Species:Temperature), scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$`Pr(>Chi)`),]

add1.test <- add1(update(logit, .~. + Species:knn.dist+ Species:Temperature +lat:Elevation), scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$`Pr(>Chi)`),]

add1.test <- add1(update(logit, .~. + Species:knn.dist+ Species:Temperature+lat:Elevation+Elevation:Imperviousness), scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$`Pr(>Chi)`),]

add1.test <- add1(update(logit, .~. + Species:knn.dist+ Species:Temperature+lat:Elevation+Elevation:Imperviousness +Age:month), scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$`Pr(>Chi)`),]


#update glm with interactions

logit_update1 <- update(logit, .~. 
+Species:knn.dist
+ Species:Temperature
+lat:Elevation
+Elevation:Imperviousness 
+Age:month)
summary(logit_update1)



drop_u1<-dropterm(logit_update1)
drop_u1<-arrange(drop_u1, AIC)
drop_u1

logit_update2 <- update(logit_update1, .~. 
- long 
- Sex
- Distance_to_water )
pop<-summary(logit_update2)
pop2<-pop[[13]]

pop2%<>%as.data.frame()

confint_mod<-as.data.frame(confint(logit_update2, level = 0.95))
 
#merge 
pop3<- merge(pop2, confint_mod, by="row.names")

pop3<-pop3[,c(1,2,6,7,3,4,5)]

pop3<-arrange(pop3, `Pr(>|z|)`)

#library(xtable)

# Convert the data frame to a table
#pop2_table <- xtable(pop2)

# Print the table to the console
#print(pop2_table, type = "html")

#library(knitr)
#kable(pop2, format = "html")



#library(stargazer)

# Create a data frame
#data <- data.frame(x = c(1, 2, 3), y = c(4, 5, 6))

# Use stargazer to create a LaTeX table
#stargazer(pop2, type = "latex")

write.csv(pop3, file = "glm_fit.csv")


####
# Get the AICc
# Get the number of parameters
df <- length(coef(logit))

# Get the number of observations
n <- length(logit$residuals)

# Calculate the AICc
AICc1 <- AIC(logit) + (2 * df / (n - df - 1))

###delta AICc is difference in 2 model AIcc

# Get the number of parameters
df2 <- length(coef(logit_update2))

# Get the number of observations
n2 <- length(logit_update2$residuals)

# Calculate the AICc
AICc2 <- AIC(logit_update2) + (2 * df2 / (n2 - df2 - 1))

# Calculate the AICc for each model
#AICc1 <- AIC(fit1) + 2 * (nrow(coef(fit1)))^2 / (n - nrow(coef(fit1)) - 1)
#AICc2 <- AIC(fit2) + 2 * (nrow(coef(fit2)))^2 / (n - nrow(coef(fit2)) - 1)

# Calculate the delta AICc
deltaAICc <- AICc2 - AICc1


###model weights

# Calculate the AIC for each model
AIC1 <- AIC(logit)
AIC2 <- AIC(logit_update2)

# Calculate the minimum AIC
minAIC <- min(AIC1, AIC2)

# Calculate the weight for each model
weight1 <- exp(-(AIC1 - minAIC) / 2)
weight2 <- exp(-(AIC2 - minAIC) / 2)

# Normalize the weights
weights <- c(weight1, weight2) / sum(c(weight1, weight2))
# higher weight is a better fit for the model

# Get the log-likelihood
loglik_base <- logLik(logit)
loglik_lu2<-logLik(logit_update2)
```

```{r}
###logit update without landuse

logit_update_LU <- update(logit_update1, .~. 
- long 
- Sex
- Distance_to_water
- description )



```

```{r}
#look for outliers
library(car)
influencePlot(logit_update2)
outlierTest(logit_update2)

#
logit_update3 <- update(logit_update2, data = data_train[-c(120),])
summary(logit_update3)
#

influencePlot(logit_update3)
outlierTest(logit_update3)

#
logit_update4 <- update(logit_update2, data = data_train[-c(120,105),])
summary(logit_update4)

#

influencePlot(logit_update4)
outlierTest(logit_update4)

#
logit_update5 <- update(logit_update2, data = data_train[-c(120,105,152),])
summary(logit_update5)

#


influencePlot(logit_update5)
outlierTest(logit_update5)



residualsqq2 <- residuals(logit_update5, type = "pearson")

# create Q-Q plot
qqnorm(residualsqq2)


logit_update_LU2<-  update(logit_update5, .~. 
- description )
```

```{r}
#test new model predictions

predict_new <- predict(logit_update5, data_test, type = 'response')
# confusion matrix
table_mat_new <- table(data_test$Distemper, predict_new >0.5)
table_mat_new

accuracy_Test_new <- sum(diag(table_mat_new)) / sum(table_mat_new)
accuracy_Test_new


#precision <- function(matrix) {
	# True positive
 #   tp <- matrix[2, 2]
	# false positive
  #  fp <- matrix[1, 2]
  # return (tp / (tp + fp))
#}

#recall <- function(matrix) {
# true positive
 #   tp <- matrix[2, 2]# false positive
  #  fn <- matrix[2, 1]
   # return (tp / (tp + fn))
#}

prec_new <- precision(table_mat_new)
prec_new
rec_new <- recall(table_mat_new)
rec_new


f1_new <- 2 * ((prec_new * rec_new) / (prec_new + rec_new))
f1_new




```


```{r}
# slim_DF<-SCWDS_with_eco_fil2[,c(2,4,5,8,10,13,15,16)]
# 
# 
# drop1.test <- drop1(logit, test="Chisq")
# drop1.test[rev(order(drop1.test$`Pr(>Chi)`)),]
# 

# Compare the base model and the improved model using a chi-squared test
dropterm(logit_update2)
# 
# set.seed(1234)
# 
# data_train2 <- create_train_test(slim_DF, 0.8, train = TRUE)
# data_test2 <- create_train_test(slim_DF, 0.8, train = FALSE)
# dim(data_train2)
# 
# 
# formula <- Distemper~.
# logit2 <- glm(formula, data = data_train2, family = 'binomial')
# summary(logit2)
# 
# 
# 
# drop2<-dropterm(logit2)
# drop2<-arrange(drop2, AIC)
# 
# 
# 
# 
# slim_DF2<-SCWDS_with_eco_fil2[,c(2,5,8,9,10,13,16)]
# 
# set.seed(12345)
# 
# data_train3 <- create_train_test(slim_DF2, 0.8, train = TRUE)
# data_test3 <- create_train_test(slim_DF2, 0.8, train = FALSE)
# dim(data_train3)
# 
# 
# formula <- Distemper~.
# logit3 <- glm(formula, data = data_train3, family = 'binomial')
# summary(logit3)
# 
# 
# 
# drop3<-dropterm(logit3)
# drop3<-arrange(drop3, AIC)




predict2 <- predict(logit_update2, data_test, type = 'response')
# confusion matrix
table_mat2 <- table(data_test$Distemper, predict >0.5)
table_mat2

accuracy_Test2 <- sum(diag(table_mat2)) / sum(table_mat2)
accuracy_Test2


prec2 <- precision(table_mat2)
prec2
rec2 <- recall(table_mat2)
rec2


f12 <- 2 * ((prec2 * rec2) / (prec2 + rec2))
f12






# Extract the residuals and fitted values
residuals <- residuals(logit_update2, type = "pearson")
fitted_values <- fitted(logit_update2)

# Create a scatter plot of the residuals and fitted values
library(ggplot2)
ggplot(data.frame(fitted_values, residuals), aes(x = fitted_values, y = residuals)) + 
  geom_point()+
  geom_smooth(method = "loess")  +
  xlab("Fitted Values") +
  ylab("Pearson Residuals") +
  ggtitle("Pearson Residuals vs Fitted Values")


###looks like our model fits the data well


###test for overfitting


# Load library


# Split the data into a training set and a test set
# set.seed(123)
# split_index <- createDataPartition(data$y, p = 0.8, list = FALSE)
# train_data <- data[split_index, ]
# test_data <- data[-split_index, ]

# Fit the model on the training set
model_OF <- glm(logit_update2, data = data_train, family = "binomial")

# Extract the residuals for the training set
train_residuals <- residuals(model_OF, type = "deviance")

# Make predictions on the test set
test_predictions <- predict(model_OF, newdata = data_test, type = "response")

# Calculate the test set deviance residuals
test_residuals <- data_test$Distemper - test_predictions

# Compare the residuals between train and test set
par(mfrow = c(1, 2))
hist(train_residuals, main = "Train Set Residuals", xlab = "Residuals", col = "blue")
hist(test_residuals, main = "Test Set Residuals", xlab = "Residuals", col = "green")

#don't seem to be overfitting


#qqPlot(logit_update2)

# extract the residuals
residualsqq <- residuals(logit_update2, type = "pearson")

# create Q-Q plot
qqnorm(residualsqq)

#data may be over dispersed, lots of outliers
#plot.new()
#qqline(residualsqq)
```

```{r}
#viz

library(sjPlot)
#plot_model(logit_update2, type = "pred", terms = c("imperviousness"))
#library(ggplot2)

# fit the GLM model
#model <- glm(y ~ x1 + x2, data = train_data)

# make predictions on the test data
#test_predictions <- predict(logit_update2, newdata = data_test)

# create a data frame with the test data and predictions
test_results <- data.frame(data_test, prediction = predict)

# plot the test data and predictions
ggplot(test_results, aes(x = Distemper, y = prediction)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("Prediction Results vs Test Data") +
  xlab("Test Data") +
  ylab("Prediction Results")

# Create a new column in the test_results data frame, which contains the predicted class based on the probability
test_results$predicted_class <- ifelse(test_results$prediction > 0.5,1,0)

# plot the test data and predictions
ggplot(test_results, aes(x = Distemper, y = predicted_class)) +
  geom_jitter(width = 0.1) +  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  ggtitle("Prediction Results") +
  xlab("Test Data") +
  ylab("Predicted Class")

```

```{r}
library(tree)

mytreeD<-tree(logit, data = data_train, split = "deviance", mincut = 10, minsize = 30, maxdepth = 3, mincriterion = 0.95)

mytree <- tree(y ~ x1 + x2 + group, data = mydata, split = "deviance", mincut = 10, minsize = 30, maxdepth = 3, mindev = 0.001, mincriterion = 0.95)


droptest<-dropterm(logit_update5)
droptest<-arrange(droptest, AIC)


dropearly<-dropterm(logit)
dropearly<-arrange(dropearly, AIC)


```
```{r}
library(rpart)
mytreedecision <- rpart(logit, data = data_train, method = "class", control = rpart.control(cp = 0.001))

plot(mytreedecision)
text(mytreedecision)

library(ggparty)
library(rpart.plot)
treeparty<-partykit::ctree(formula=Distemper ~ Species + Age + month + lat + knn.dist + 
    Elevation + Precipitation + Temperature + Imperviousness + 
    description 
, data = data_train)

ggparty::gg_tree(treeparty)


prp(mytreedecision)
```
```{r}

# Fit a logistic regression model
#model <- glm(y ~ x1 + x2 + x3, data = mydata, family = "binomial")

# Fit a logistic regression model
#model <- glm(y ~ x1 + x2 + x3, data = mydata, family = "binomial")

# Extract the coefficients
coef <- coef(logit_update5)

# Calculate the log odds ratios and corresponding confidence intervals
logodds <- exp(coef)
logoddsCI <- exp(confint.default(logit_update5))

# Create a results data frame
results <- data.frame(coef, logodds, logoddsCI)

# Print the results
print(results)


```
```{r}
# Load the rsq package
library(rsq)
library(arm)
# Fit a GLM model
#model <- glm(y ~ x1 + x2 + x3, data = mydata, family = "binomial")

# Calculate standardized coefficients using the rsq package
std_coef <- standardized(logit_update5)

# Print the standardized coefficients
print(std_coef)


# Fit a GLM model
#model <- glm(y ~ x1 + x2 + x3, data = mydata, family = "binomial")

# Calculate standardized coefficients manually
coef_std <- coef(logit_update5) / (summary(logit_update5)$dispersion * summary(logit_update5)$coefficients[, "Std. Error"])

# Print the standardized coefficients
print(coef_std)


# Create a dataframe with the standardized coefficients
df_coef_std <- data.frame(var = names(coef_std), std_coef = coef_std)

# Order the dataframe by the absolute size of the standardized coefficients
df_coef_std_ordered <- df_coef_std %>% arrange(desc(abs(std_coef)))


#add to main table 

pop3
df_coef_std

colnames(pop3)[1]<-"var"


full_results_df<-left_join(pop3,df_coef_std)

full_results_df_ordered <- full_results_df %>% arrange(desc(abs(std_coef)))


write.csv(full_results_df_ordered, file = "glm_fit_std_coef.csv")

```

```{r}

logit_update5
droplate<-dropterm(logit_update5)
droplate<-arrange(droplate, AIC)


```
```{r}
# Fit a GLM model
#myglm <- glm(response ~ predictor1 + predictor2, data=mydata, family=binomial)

# Extract coefficient estimates and standard errors
coef_est <- coef(logit_update5)
coef_se <- summary(logit_update5)$coef[,2]

# Calculate odds ratios and confidence intervals
odds_ratios <- exp(coef_est)
conf_int_low <- exp(coef_est - 1.96*coef_se)
conf_int_high <- exp(coef_est + 1.96*coef_se)

# # Create a bar plot with error bars
# plot(odds_ratios, ylab="Odds Ratio", xlab="Predictor", ylim=c(0, max(odds_ratios)*1.2), 
#      main="Odds Ratio Plot")
# arrows(x0=1:length(odds_ratios), y0=conf_int_low, y1=conf_int_high, 
#        angle=90, code=3, length=0.05, col="blue")
# axis(side=1, at=1:length(odds_ratios), labels=names(odds_ratios), las=2)


# Create a data frame for plotting
plot_data <- data.frame(predictor=names(odds_ratios),
                        odds_ratio=odds_ratios,
                        conf_int_low=conf_int_low,
                        conf_int_high=conf_int_high)

# Create a plot with error bars
ggplot(plot_data, aes(x=predictor, y=odds_ratio)) +
  geom_bar(stat="identity", fill="lightblue", alpha=0.5) +
  geom_errorbar(aes(ymin=conf_int_low, ymax=conf_int_high), 
                width=0.2, size=1, color="blue") +
  labs(x="Predictor", y="Odds Ratio", 
       title="Odds Ratio Plot") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
```

```{r}
# Load the necessary libraries
library(ggplot2)
library(dplyr)

# Fit the GLM model and store the results
#model <- glm(formula = formula, family = binomial(link = "logit"), data = data)
resultsOR <- broom::tidy(logit_update5)

# Calculate the odds ratios and confidence intervals
resultsOR <- resultsOR %>%
  mutate(odds_ratio = exp(estimate)) %>%
  mutate(lower_ci = exp(estimate - 1.96 * std.error),
         upper_ci = exp(estimate + 1.96 * std.error))

# Create a ggplot2 object for the odds ratios
plot <- ggplot(resultsOR, aes(x = term, y = odds_ratio, ymin = lower_ci, ymax = upper_ci)) +
  geom_pointrange(color = "steelblue", size = 1.5, alpha = 0.8) +
  coord_flip() +
  labs(x = "", y = "Odds Ratio", title = "Odds Ratio Plot") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

# Display the plot
plot



```


<!-- ```{r raccoons} -->
<!-- SCWDS_rac<-SCWDS_rac[sample(1:nrow(SCWDS_rac)), ] -->
<!-- SCWDS_rac<-SCWDS_rac[,-2] -->
<!-- set.seed(1234) -->

<!-- data_trainr <- create_train_test(SCWDS_rac, 0.8, train = TRUE) -->
<!-- data_testr <- create_train_test(SCWDS_rac, 0.8, train = FALSE) -->
<!-- dim(data_trainr) -->


<!-- formula <- Distemper~. -->
<!-- logitr <- glm(formula, data = data_trainr, family = 'binomial') -->
<!-- summary(logitr) -->

<!-- dropr<-dropterm(logitr) -->
<!-- dropr<-arrange(dropr, AIC) -->



<!-- ``` -->

<!-- ```{r} -->
<!-- # box plot rac temp -->
<!-- SCWDS_rac$Distemper%<>%as.factor() -->


<!-- ggplot(SCWDS_rac, aes(x = Distemper, y = Temperature)) + -->
<!--     geom_boxplot() + -->
<!--     stat_summary(fun = mean, -->
<!--         geom = "point", -->
<!--         size = 3, -->
<!--         color = "steelblue") + -->
<!--     theme_classic()+scale_y_log10()+geom_signif(comparisons = list(c("0", "1")),  -->
<!--               map_signif_level=TRUE) -->


<!-- ``` -->

<!-- ```{r} -->
<!-- #run some chisq tests -->
<!-- #month -->
<!-- chisq.test(SCWDS_with_eco_fil1$month,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->

<!-- #age -->
<!-- chisq.test(SCWDS_with_eco_fil1$Age,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->
<!-- #descriptoion -->
<!-- chisq.test(SCWDS_with_eco_fil1$description,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->
<!-- #species #sig -->
<!-- chisq.test(SCWDS_with_eco_fil1$Species,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->
<!-- #class -->
<!-- chisq.test(SCWDS_with_eco_fil1$class,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->
<!-- #sex -->
<!-- chisq.test(SCWDS_with_eco_fil1$Sex,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->
<!-- #state #sig -->
<!-- chisq.test(SCWDS_with_eco_fil1$State,SCWDS_with_eco_fil1$Distemper, correct=FALSE) -->
<!-- ``` -->


<!-- ```{r} -->

<!-- # Start with the full model -->
<!-- #base_model <- glm(y ~ x1 + x2 + x3 + x4, data = data, family = binomial) -->

<!-- # Perform backward stepwise selection -->
<!-- model_step <- step(logit, direction = "backward") -->

<!-- # Print the summary of the final model -->
<!-- summary(model_step) -->




<!-- ``` -->